# Monet Style Image Generation with GANs
This project is part of the Kaggle competition Getting Started with GANs. The challenge revolves around creating a Generative Adversarial Network (GAN) capable of generating high-quality images in the style of the renowned artist Claude Monet. This task merges the fields of computer vision and artistic style transfer, leveraging cutting-edge deep learning techniques to reproduce Monet’s distinct artistic flair.

Generative Adversarial Networks consist of two neural networks: a generator and a discriminator. The generator's goal is to create Monet-like images, while the discriminator's role is to distinguish between real Monet paintings and those generated by the generator. By training these networks adversarially, we aim to create images so convincing that they are indistinguishable from authentic Monet artworks.


###  Approach and Methodology
##### Data Preprocessing
The provided dataset contains Monet paintings and photographs of various landscapes. To train the GAN effectively, all images are resized to 256x256 pixels and normalized to fall within the range [-1, 1], a common practice in deep learning that facilitates model convergence. The TFRecords format is utilized for efficient data storage and loading during training.

##### Model Architecture
This project employs the CycleGAN framework, which is particularly well-suited for unpaired image-to-image translation tasks. CycleGAN enables style transfer by training two generators and two discriminators, ensuring consistency between the input and output images while preserving important content details.

Generator: Responsible for converting landscape photographs into Monet-style paintings. It uses convolutional layers and residual blocks to capture the intricate details of Monet's brushstrokes and color palette.
Discriminator: Aims to classify images as either real Monet paintings or generated ones. By training the discriminator to distinguish between the two, the generator is pushed to improve its image generation quality.
Training Strategy
The generator and discriminator are trained adversarially. The generator’s objective is to create Monet-style images that fool the discriminator, while the discriminator learns to accurately differentiate between real and generated images. To improve training stability, loss functions such as adversarial loss, cycle-consistency loss, and identity loss are used.

### Evaluation Metrics
The primary metric for evaluating the quality of generated images is MiFID (Memorizable-informed Fréchet Inception Distance), which extends the traditional FID metric by incorporating a memorization penalty. This ensures that generated images are not direct copies of training samples but instead demonstrate originality while maintaining artistic coherence.

How MiFID Works
Fréchet Inception Distance (FID): Measures the similarity between distributions of real and generated images in a feature space extracted from a pre-trained Inception network.
Memorization Penalty: Adds a penalty for generated images that closely resemble training samples, ensuring that the GAN does not overfit to the training dataset.
The combination of these metrics provides a comprehensive assessment of the quality and diversity of the generated images.

###  Results and Observations
The trained CycleGAN successfully generates Monet-style images that capture the essence of Monet's artistry, including his signature use of color, texture, and composition. The generated images demonstrate:

High visual fidelity and stylistic consistency with real Monet paintings.
Diversity in content and composition, avoiding over-replication of the training dataset.
The generator achieved competitive MiFID scores, showcasing its ability to generalize well to unseen data while maintaining artistic quality.
